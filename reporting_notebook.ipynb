{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Notebook for advanced stats and visualization.\n", 
    "# Run this after you generate output. Change output_dir to the output directory from Auto-Cat\n",
    "# Update the settings in plot_top_levels_dendrogram to change the resulting image size.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from typing import Dict, Any\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Set the output directory\n",
    "output_dir = 'output3'\n",
    "\n",
    "# Load the data\n",
    "def load_embeddings(file_path: str):\n",
    "    with np.load(file_path, allow_pickle=True) as data:\n",
    "        return {\n",
    "            'embeddings': data['embeddings'],\n",
    "            'ids': data['ids'].tolist(),\n",
    "            'metadatas': data['metadatas'].tolist()\n",
    "        }\n",
    "\n",
    "embeddings = load_embeddings(os.path.join(output_dir, \"embeddings.npz\"))\n",
    "\n",
    "# Load clustering results\n",
    "clustering_methods = [\"kmeans\", \"dbscan\", \"agglomerative\"]\n",
    "all_clusters = {}\n",
    "for method in clustering_methods:\n",
    "    clusters_file = os.path.join(output_dir, f\"{method}_clusters.npy\")\n",
    "    if os.path.exists(clusters_file):\n",
    "        all_clusters[method] = np.load(clusters_file)\n",
    "\n",
    "# Load linkage matrix for agglomerative clustering\n",
    "linkage_matrix = np.load(os.path.join(output_dir, \"agglomerative_linkage.npy\"))\n",
    "\n",
    "# Load category analysis results\n",
    "all_categories = {}\n",
    "for method in clustering_methods:\n",
    "    category_file = os.path.join(output_dir, f\"{method}_report\", \"detailed_report.txt\")\n",
    "    if os.path.exists(category_file):\n",
    "        categories = {}\n",
    "        with open(category_file, 'r') as f:\n",
    "            current_category = None\n",
    "            for line in f:\n",
    "                if line.startswith(\"Category \"):\n",
    "                    current_category = int(line.split()[1].strip(':'))\n",
    "                    categories[current_category] = {\"size\": 0, \"common_words\": [], \"representative_items\": []}\n",
    "                elif line.strip().startswith(\"Size:\"):\n",
    "                    categories[current_category][\"size\"] = int(line.split(\":\")[1].strip())\n",
    "                elif line.strip().startswith(\"Common Words:\"):\n",
    "                    categories[current_category][\"common_words\"] = line.split(\":\")[1].strip().split(\", \")\n",
    "                elif line.strip().startswith(\"Representative Items:\"):\n",
    "                    items = []\n",
    "                    for item_line in f:\n",
    "                        if item_line.strip() and not item_line.startswith(\"Category\"):\n",
    "                            items.append(item_line.strip())\n",
    "                        else:\n",
    "                            break\n",
    "                    categories[current_category][\"representative_items\"] = items\n",
    "        all_categories[method] = categories\n",
    "\n",
    "# Improved dendrogram function\n",
    "def plot_top_levels_dendrogram(linkage_matrix: np.ndarray, categories: Dict[int, Dict[str, Any]], n_top_levels: int = None):\n",
    "    plt.figure(figsize=(80, 45))  # 80x45 inches at 96 DPI is approximately 7680x4320 pixels\n",
    "    \n",
    "    def llf(id):\n",
    "        if id < len(categories):\n",
    "            common_words = categories[id][\"common_words\"]\n",
    "            return \", \".join(common_words[:3]) if common_words else f\"Cluster {id}\"\n",
    "        return f\"Cluster {id}\"\n",
    "    \n",
    "    R = dendrogram(\n",
    "        linkage_matrix,\n",
    "        truncate_mode=None,  # Show full tree\n",
    "        no_labels=True,\n",
    "        leaf_rotation=0,\n",
    "        leaf_font_size=16,\n",
    "        show_contracted=True,\n",
    "    )\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    \n",
    "    for i, d, c in zip(R['icoord'], R['dcoord'], R['color_list']):\n",
    "        x = 0.5 * sum(i[1:3])\n",
    "        y = d[1]\n",
    "        if y > 0:  # Only annotate internal nodes\n",
    "            node_id = R['leaves'][int(x/10)]  # Approximate mapping of x-coordinate to node id\n",
    "            label = llf(node_id)\n",
    "            ax.plot(x, y, 'o', c=c)\n",
    "            ax.annotate(label, (x, y), xytext=(0, 5),\n",
    "                        textcoords='offset points',\n",
    "                        va='bottom', ha='center',\n",
    "                        bbox=dict(boxstyle='round,pad=0.5', fc='white', alpha=0.7),\n",
    "                        fontsize=12, rotation=90)\n",
    "\n",
    "    plt.title('Hierarchical Clustering Dendrogram with Category Labels', fontsize=24)\n",
    "    plt.xlabel('Sample Index', fontsize=20)\n",
    "    plt.ylabel('Distance', fontsize=20)\n",
    "    \n",
    "    # Manually adjusting margins to avoid tight_layout warning\n",
    "    plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05)\n",
    "    \n",
    "    # Save the figure with high DPI to ensure sharpness at 8K resolution\n",
    "    plt.savefig(\"full_dendrogram_with_labels_8k.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Generate the improved dendrogram with labels on forks\n",
    "plot_top_levels_dendrogram(linkage_matrix, all_categories['agglomerative'])\n",
    "\n",
    "\n",
    "# Clustering comparison\n",
    "def compare_clustering_methods(all_categories: Dict[str, Dict[int, Dict[str, Any]]]):\n",
    "    comparison = {\n",
    "        method: {\n",
    "            \"num_categories\": len(categories),\n",
    "            \"avg_category_size\": sum(cat[\"size\"] for cat in categories.values()) / len(categories),\n",
    "            \"max_category_size\": max(cat[\"size\"] for cat in categories.values()),\n",
    "            \"min_category_size\": min(cat[\"size\"] for cat in categories.values()),\n",
    "        }\n",
    "        for method, categories in all_categories.items()\n",
    "    }\n",
    "    df = pd.DataFrame(comparison).T\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    df.plot(kind='bar', y=['num_categories', 'avg_category_size'], ax=plt.gca())\n",
    "    plt.title(\"Comparison of Clustering Methods\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"clustering_comparison.png\"))\n",
    "    plt.show()\n",
    "    \n",
    "    return df\n",
    "\n",
    "comparison_df = compare_clustering_methods(all_categories)\n",
    "print(comparison_df)\n",
    "\n",
    "# Word cloud generation\n",
    "def generate_word_cloud(categories: Dict[int, Dict[str, Any]], method: str):\n",
    "    all_words = ' '.join([' '.join(cat['common_words']) for cat in categories.values() if cat['common_words']])\n",
    "\n",
    "    if not all_words:\n",
    "        print(f\"No common words found for {method}. Skipping word cloud generation.\")\n",
    "        return\n",
    "\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_words)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Word Cloud for {method.capitalize()} Clustering\")\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.savefig(os.path.join(output_dir, f\"{method}_word_cloud.png\"))\n",
    "    plt.show()\n",
    "\n",
    "# Generate word clouds for each clustering method\n",
    "for method in clustering_methods:\n",
    "    generate_word_cloud(all_categories[method], method)\n",
    "\n",
    "# Category size distribution\n",
    "def plot_category_size_distribution(categories: Dict[int, Dict[str, Any]], method: str):\n",
    "    sizes = [cat['size'] for cat in categories.values()]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(sizes, kde=True)\n",
    "    plt.title(f\"Category Size Distribution for {method.capitalize()} Clustering\")\n",
    "    plt.xlabel(\"Category Size\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.savefig(os.path.join(output_dir, f\"{method}_category_size_distribution.png\"))\n",
    "    plt.show()\n",
    "\n",
    "# Plot category size distribution for each clustering method\n",
    "for method in clustering_methods:\n",
    "    plot_category_size_distribution(all_categories[method], method)\n",
    "\n",
    "# Top categories analysis\n",
    "def analyze_top_categories(categories: Dict[int, Dict[str, Any]], method: str, top_n: int = 10):\n",
    "    sorted_categories = sorted(categories.items(), key=lambda x: x[1]['size'], reverse=True)\n",
    "    top_categories = sorted_categories[:top_n]\n",
    "    \n",
    "    print(f\"Top {top_n} Categories for {method.capitalize()} Clustering:\")\n",
    "    for i, (cat_id, cat_info) in enumerate(top_categories, 1):\n",
    "        print(f\"{i}. Category {cat_id}\")\n",
    "        print(f\"   Size: {cat_info['size']}\")\n",
    "        print(f\"   Common Words: {', '.join(cat_info['common_words'][:5])}\")\n",
    "        print(f\"   Sample Item: {cat_info['representative_items'][0][:100]}...\")\n",
    "        print()\n",
    "\n",
    "# Analyze top categories for each clustering method\n",
    "for method in clustering_methods:\n",
    "    analyze_top_categories(all_categories[method], method)\n",
    "\n",
    "def plot_category_word_heatmap(categories: Dict[int, Dict[str, Any]], method: str):\n",
    "    unique_words = set()\n",
    "    for cat in categories.values():\n",
    "        unique_words.update(cat['common_words'])\n",
    "    \n",
    "    word_index = {word: idx for idx, word in enumerate(unique_words)}\n",
    "    category_names = list(categories.keys())\n",
    "    \n",
    "    heatmap_data = np.zeros((len(category_names), len(unique_words)))\n",
    "    \n",
    "    for i, (cat_id, cat_info) in enumerate(categories.items()):\n",
    "        for word in cat_info['common_words']:\n",
    "            if word in word_index:\n",
    "                heatmap_data[i, word_index[word]] = 1\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    sns.heatmap(heatmap_data, cmap=\"YlGnBu\", xticklabels=unique_words, yticklabels=category_names)\n",
    "    plt.title(f\"Heatmap of Categories and Common Words for {method.capitalize()} Clustering\")\n",
    "    plt.xlabel(\"Common Words\")\n",
    "    plt.ylabel(\"Categories\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f\"{method}_category_word_heatmap.png\"))\n",
    "    plt.show()\n",
    "\n",
    "# Generate heatmaps for each clustering method\n",
    "for method in clustering_methods:\n",
    "    plot_category_word_heatmap(all_categories[method], method)\n",
    "    \n",
    "def plot_sankey_diagram_for_clusters(categories: Dict[int, Dict[str, Any]], method: str):\n",
    "    from matplotlib.sankey import Sankey\n",
    "\n",
    "    sankey = Sankey(unit=None)\n",
    "    for cat_id, cat_info in categories.items():\n",
    "        size = cat_info['size']\n",
    "        # TODO Replace logic to determine flows between categories\n",
    "        sankey.add(flows=[size, -size], labels=[f\"Cat {cat_id} start\", f\"Cat {cat_id} end\"], orientations=[1, -1])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 7))\n",
    "    sankey.finish()\n",
    "    plt.title(f\"Sankey Diagram for {method.capitalize()} Clustering\")\n",
    "    plt.savefig(os.path.join(output_dir, f\"{method}_sankey_diagram.png\"))\n",
    "    plt.show()\n",
    "\n",
    "plot_sankey_diagram_for_clusters(all_categories['agglomerative'], 'agglomerative')\n"
   ],
   "id": "89912635019afbed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d0000070b78d8c0a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
